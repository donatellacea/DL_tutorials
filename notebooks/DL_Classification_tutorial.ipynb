{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fbdbc75",
   "metadata": {},
   "source": [
    "![logo](https://github.com/donatellacea/DL_tutorials/blob/main/notebooks/figures/1128-191-max.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040a619e",
   "metadata": {},
   "source": [
    "# Image classification with Deep Learning \n",
    "---\n",
    "\n",
    "With the term **Machine Learning** (ML) we define a set of algorithms and methods that provide a machine with the ability to learn automatically and improve from experience without being explicitly programmed.\n",
    "When we have labeled data, we can use the label to guide the learning process, and this is called **Supervised learning**. If data are not labeled, it means that we don't have a guide or supervision, and this is called **Unsupervised learning**.\n",
    "Within Supervised learning, we can have two different kinds of problems:\n",
    " - **Regression problem**: the task of predicting a continuous quantity,  \n",
    " - **Classification problem**: the task of predicting a label or a class (discrete values).\n",
    "\n",
    "This tutorial will show you how to perform classification with Deep Neural Network (NN) on images. We will work with two public datasets, and we will see a binary classification and a multi-class classification problem. \n",
    "\n",
    "In order to start working on the notebook, click on the following button, this will open this page in the Colab environment and you will be able to execute the code on your own.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/donatellacea/DL_tutorials/blob/main/notebooks/DL_Classification_tutorial.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58bec64",
   "metadata": {},
   "source": [
    "### Setup the environment\n",
    "\n",
    "**If you already did this step for the Tensorflow Playground tutorial, you can skip the setup section and start with the Import and Install section. Otherwise, complete the next step before starting the tutorial.**\n",
    "\n",
    "Now that you are visualizing the notebook in Colab, run the next cell, in order to create a folder in your Google Drive. All the files for this tutorial will be uploaded to this folder. After the first execution you might receive some warning and notification, please follow these instructions:\n",
    "1. Warning: This notebook was not authored by Google. Click on Run anyway.\n",
    "2. Permit this notebook to access your Google Drive files? Click on Yes, and select your account.\n",
    "3. Google Drive for desktopÂ wants to access your Google Account. Click on 'Allow'.\n",
    "\n",
    "At this point, a folder has been created and you can navigate it through the lefthand panel in Colab, you might also have received an email that informs you about the access on your Google Drive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283012ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folder in your Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ea4ba3",
   "metadata": {},
   "source": [
    "Execute the next cells to clone the repository from GitHub, so the important files and notebooks for this tutorial will be downloaded to your working folder on the Drive that you created in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43769c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd drive/MyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eb3263",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/donatellacea/DL_tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26d77c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd DL_tutorials/notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e277648b",
   "metadata": {},
   "source": [
    "### Import and install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e01fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install alive_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8fcf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to import the main packages we will use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import sklearn\n",
    "import random\n",
    "random.seed(1)\n",
    "import matplotlib.pyplot as plt \n",
    "import PIL\n",
    "import plotly.graph_objects as go\n",
    "import scipy.ndimage\n",
    "from skimage import io \n",
    "from alive_progress import alive_bar\n",
    "from check_file import *\n",
    "from utils import *\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1918d1f3",
   "metadata": {},
   "source": [
    "## Binary Classification\n",
    "---\n",
    "\n",
    "In this problem, we will use the Lung CT scans dataset in order to predict whether the patient has Codiv-19 or not. Since the output can be positive or negative, this is a classic example of **binary classification**. \n",
    "\n",
    "### Dataset \n",
    "The dataset, available on Kaggle (https://www.kaggle.com/datasets/luisblanche/covidct), will be downloaded in your google drive folder that we will create in the first step of the tutorial.\n",
    "\n",
    "It counts in a total of 746 images divided as follows:\n",
    "- 397 No Covid\n",
    "- 349 Covid\n",
    "\n",
    "The images, i.e. CT scans, are obtained through Computed Tomography, a medical imaging technique used in radiology (x-ray) to obtain detailed internal images of the body noninvasively for diagnostic purposes. Only with proper training is it possible to interpret the scans, so without a radiology/medical background, it is tough to understand the presence of Covid-19 from the scan. But we will see that a well-trained NN can help the technicians and doctors diagnose this kind of disease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d421c0",
   "metadata": {},
   "source": [
    "Run the next cell to download the data, you should see a folder that contains two subfolders one for each class, Covid and No-Covid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bd0c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path\n",
    "main_path = '/content/drive/MyDrive/DL_tutorials/notebooks/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac85b2c",
   "metadata": {},
   "source": [
    "The next cell will download the dataset to your google drive. From there you can eventually look at the images or download them on your own machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ce12fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L https://www.dropbox.com/s/ynxtbh7t0mts30k/Dataset_CT_lungs.zip?dl=1 > /content/drive/MyDrive/DL_tutorials/notebooks/Dataset_CT_lungs.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444494c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.unpack_archive(main_path + 'Dataset_CT_lungs.zip', main_path)\n",
    "shutil.rmtree(main_path + '__MACOSX')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7539cf63",
   "metadata": {},
   "source": [
    "Now, let's have a look at the kind of images we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0103b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the path to each folder\n",
    "data_path = main_path + '/Dataset_CT_lungs/'\n",
    "pos_files = glob.glob(os.path.join(data_path, \"CT_COVID\",'*.*'))\n",
    "neg_files = glob.glob(os.path.join(data_path, 'CT_NonCOVID','*.*'))\n",
    "images = pos_files + neg_files\n",
    "num_total = len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a9bc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 9 random CT scans from the dataset to see how they look like\n",
    "plt.subplots(3, 3, figsize=(8, 8)) \n",
    "num_fig = 9\n",
    "ax_name = ['No Covid'] * num_fig\n",
    "for i, number in enumerate(random.sample(range(num_total), num_fig)):\n",
    "    im = PIL.Image.open(images[number])\n",
    "    arr = np.array(im)\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    if 'CT_COVID' in images[number]:        \n",
    "        ax_name[i] = 'Covid'\n",
    "    plt.xlabel(ax_name[i], fontsize=15)\n",
    "    plt.imshow(arr, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e170a1",
   "metadata": {},
   "source": [
    "Let's see how the [Teachable Machine](https://teachablemachine.withgoogle.com/) is able to recognize Covid from the CT scans. If you didn't do the previous tutorial on the Teachable Machine, and you have any doubt about it, you can open the respective notebook where you can find some more information.\n",
    "\n",
    "You can upload the dataset directly from the drive, but it might be quicker to download the dataset on your own computer and do the upload from there, so it will take only a couple of minutes.\n",
    "Crate the label for the two classes and upload the data (Do not use all the images, but keep a couple of images from each class, so that you can use them later in the preview.)\n",
    "\n",
    "Now, start the training of the teachable machine with the panel Under the Hood opened to look at the learning curves and the accuracies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f499ce",
   "metadata": {},
   "source": [
    "### Model evaluation - learning curves\n",
    "\n",
    "Your goal is to check whether the model is able to recognize the disease or not and with which performances. To test the model you can either upload a single scan from the folders and see if the predicted output is correct.\n",
    "But to have a wider comprehension of what is happening, open the under the hood panel and check the learning curves during the training.\n",
    "\n",
    "**Accuracy per epoch**\n",
    "\n",
    "Accuracy is one of the evaluation metrics we can use to evaluate how good a model is. It can be defined as the number of samples correctly classified over the total number of samples.\n",
    "\n",
    "<center>\n",
    "$\\text{Accuracy} = \\dfrac{\\text{# of sample correctly classified}}{\\text{total # of sample}}$\n",
    "</center>\n",
    "\n",
    "\n",
    "Looking at the accuracy plot over the epochs we can say that the model is not perming badly.\n",
    "\n",
    "\n",
    "\n",
    "**Loss per epoch**\n",
    "\n",
    "Another interesting way to see if the model is correctly learning is to look at the loss function at different epochs. A NN works trying to minimize the difference between the prediction and the label, this is usually described through a *loss function*. The network is learning if the loss function is decreasing over time.\n",
    "What is the difference between the training and the test curve?\n",
    "\n",
    "According to you, which might be the reason? Discuss it with your team and think about possible changes that could improve the model's performance.\n",
    "Run the next cell to check whether your answer is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01cf2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to have the answer to the first question \n",
    "check_task_tm_2_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd33558",
   "metadata": {},
   "source": [
    "**Confusion matrix**\n",
    "\n",
    "Sometimes accuracy is not always enough to evaluate a model. Let's see that with an example. Let's assume that we have 10 patients and only one has a disease. If our model predicts that a patient is always normal, it means that its accuracy would be $\\frac{9}{10} = 0.90$, which is pretty high, even if the model is not giving us relevant information since we are more interested in detecting the disease instead of only having such a high accuracy and missing relevant informations.\n",
    "\n",
    "For this reason, it is interesting to introduce other metrics such as sensitivity and specificity.\n",
    "- **sensitivity**: represents the true positive rate (in terms of probability is the probability of predicting positive given that the patient has the disease);\n",
    "- **specificity**: represents the true negative rate (i.e. the probability of predicting negative, given that the patient is normal).\n",
    "\n",
    "This information is usually summarized in a table, called a confusion matrix, used to look at the performance of the classifier in form of a table. The columns represent the Groundtruth (GT) and the columns are the output predicted by the model. Each cell corresponds to the number of the element corresponding to each GT/model prediction combination and is called:\n",
    "- True Positive (TP): when both GT and the prediction are positive\n",
    "- False Negative (FN): when the GT is positive but the output is negative\n",
    "- False Positive (FP): when the GT is negative (i.e. normal patient) but the output is positive\n",
    "- True negative: when both GT and the prediction are negative\n",
    "\n",
    "In medical applications, especially FN and FP should be reduced as much as possible in order to avoid missing the detection of a disease or alarming people who are actually sane.\n",
    "\n",
    "<div>\n",
    "<img src=\"https://github.com/donatellacea/DL_tutorials/blob/main/notebooks/figures/confusionmatrix.png?raw=true\" width=\"300\" height=\"200\"/>\n",
    "</div>\n",
    "\n",
    "To see the confusion matrix of our model, click the confusion matrix button in the 'Under the hood' panel. You will notice that, even if the model is performig well, there are still some FP and TN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763da77b",
   "metadata": {},
   "source": [
    "As you can see the DL algorithm, even if it is not perfect, is able to recognize Covid and no-Covid cases, a difficult task for a technician to perform and impossible for ordinary people with no medical background to undertake.\n",
    "\n",
    "Now that we explored a binary classification example through the Teachable Machine, let's have a closer look at a NN over a different dataset for multi-class classification. In the next part of the tutorial, you will directly see a coding example of a deep neural network, in order to see what hides behind an interface like the one we used in the first section of this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4921c9",
   "metadata": {},
   "source": [
    "#### Extra exercise\n",
    "\n",
    "Come back here later or after the lesson to solve this small exercise and review what we learned.\n",
    "\n",
    "According to what we explained, could you compute the sensitivity and specificity of this model? \n",
    "Insert your solution in the following cell and run to check whether your answer is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b394733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsitute None with the values that you read in the confusion matrix created on the Teachable Machine\n",
    "confusion_matrix = []\n",
    "confusion_matrix.append(None) # 'Class covid & Pred Covid'\n",
    "confusion_matrix.append(None) # 'Class covid & Pred No Covid'\n",
    "confusion_matrix.append(None) # 'Class No Covid & Pred Covid'\n",
    "confusion_matrix.append(None) # 'Class No Covid & Pred No Covid'\n",
    "\n",
    "#Subsitute None in the specificity and sensitivity field with your solution (approx at the order 10^-2)\n",
    "sensitivity = None\n",
    "specificity = None\n",
    "\n",
    "check_task_tm_2_2(confusion_matrix, sensitivity, specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddfe01d",
   "metadata": {},
   "source": [
    "## Multi-class Classification\n",
    "---\n",
    "\n",
    "In this problem, we will use the MedNIST dataset in order to predict whether the image belongs to one of the six possible classes. Since the output can be positive or negative, this is a classic example of **multi-class classification**. \n",
    "\n",
    "### Dataset \n",
    "\n",
    "The [MedNIST](https://github.com/Project-MONAI/MONAI/blob/master/examples/notebooks/mednist_tutorial.ipynb), was gathered from several sets from TCIA, the RSNA Bone Age Challenge, and the NIH Chest X-ray dataset and is kindly made available by Dr. Bradley J. Erickson M.D., Ph.D. (Department of Radiology, Mayo Clinic).\n",
    "\n",
    "The original dataset counts more than 50k images, which we reduced for the purposes of this tutorial. Run the following commands to download the dataset in your drive and unzip it. Note that this step might take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7288aacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L https://www.dropbox.com/s/wrbfk4o63f3cn5k/MedNIST_0.5.zip?dl=1 > /content/drive/MyDrive/DL_tutorials/notebooks/MedNIST_0.5.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee025fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.unpack_archive(main_path + 'MedNIST_0.5.zip', main_path)\n",
    "shutil.rmtree(main_path + '__MACOSX')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6791e6c9",
   "metadata": {},
   "source": [
    "Now let's have a look at the data.\n",
    "First, we need to save all the image names in a dataframe (df), i.e. a table, to have direct and quick access to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e9d0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, mp = get_MedNIST_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4f59be",
   "metadata": {},
   "source": [
    "Now, let's see how many possible classes we have and their names and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ad177b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b40bce",
   "metadata": {},
   "source": [
    "And finally, we can plot some random samples from the dataset to have a closer look a the images. Before we start building our classification model, run the next cell and take some time to analyze the images, and try to anticipate how the network will behave.\n",
    "\n",
    "Which classes do you expect will be harder to classify and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3acc2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(4, 4, figsize=(8, 8))\n",
    "random.seed(7) \n",
    "for i, k in enumerate(random.sample(range(len(df)), 16)):\n",
    "    im = PIL.Image.open(main_path + \"MedNIST_0.5/\" + df[0].iloc[k])\n",
    "    arr = np.array(im)\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.xlabel(df[2].iloc[k])\n",
    "    plt.imshow(arr, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adf38eb",
   "metadata": {},
   "source": [
    "### Define the structure of the Convolutional Neural Network (CNN)\n",
    "\n",
    "The network we build is formed by several hidden layers, as shown in the image ([Image credit](https://www.mathworks.com/videos/introduction-to-deep-learning-what-are-convolutional-neural-networks--1489512765771.html)).\n",
    "The aim of each layer is briefly explained below.\n",
    "\n",
    "<div>\n",
    "<img src=\"https://github.com/donatellacea/DL_tutorials/blob/main/notebooks/figures/cnn.png?raw=true\" width=\"500\" height=\"300\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "**Convolutional layer**: convolution is a mathematical word for what is essentially a moving window or filter across the image being studied. As the filter slides over the images and the dot products between the pixel values and the filter are computed, creating the so-called convolved feature map (see image below - [credit](https://media4.giphy.com/media/i4NjAwytgIRDW/giphy.gif?cid=ecf05e477z2u4ge19e34frejcm5q6o228fiyohcg0viafep7&rid=giphy.gif&ct=g)).\n",
    "<div>\n",
    "<img src=\"https://media4.giphy.com/media/i4NjAwytgIRDW/giphy.gif?cid=ecf05e477z2u4ge19e34frejcm5q6o228fiyohcg0viafep7&rid=giphy.gif&ct=g\" width=\"300\" height=\"200\"/>\n",
    "</div>\n",
    "\n",
    "**Max pooling layer**: It is another sliding window type technique, but instead of applying weights as in the convolution, it applies the max function over the contents of the window. A pooling layer is a way to subsample an input feature map or output from the convolutional layer that has already extracted salient features from an image in our case, this is also called downsampling.\n",
    "\n",
    "**Dropout layer**: dropout removes a percentage of the neuron connections - helping to prevent overfitting by reducing the feature space for convolutional and, especially, dense layers.\n",
    "\n",
    "**Linear layer**: The linear layer is used in the final stages of the neural network. It is also called a fully connected layer. This layer helps in changing the dimensionality of the output from the preceding layer so that the model can easily define the relationship between the values of the data in which the model is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e79038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=8, kernel_size=(3,3)) #out_channels=32\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3,3)) # in_channels=32\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.lin1 = nn.Linear(3136, 64)\n",
    "        self.lin2 = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x) # test with no dropout\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.lin2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55df03bc",
   "metadata": {},
   "source": [
    "### Set up the parameters\n",
    "\n",
    "We define the hyperparameters which, unlike the parameters that describe the model itself, characterize the learning process. In particular, we define:\n",
    "\n",
    "- in_channels: number of input channels\n",
    "- num_classes = number of possible output., i.e. the class that can be predicted (in the case of the Covid dataset the number of classes is 2; in this case, the classes present in the dataset are 6)\n",
    "- lr = learning rate is the step size during the training process that determines the speed and how well the model trains.\n",
    "- batch_size = number of samples processed before the model is updated, it's often set as a power of 2.\n",
    "- num_epochs = number of iterations over the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79b3604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device in case it is possible to access a GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Number of input and output\n",
    "in_channels = 1\n",
    "num_classes = 6\n",
    "\n",
    "# Hyperparameters\n",
    "lr = 0.0001\n",
    "batch_size = 64\n",
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6899cc38",
   "metadata": {},
   "source": [
    "### Train-test split\n",
    "\n",
    "No matter if we are dealing with classification or regression problems, a crucial aspect of determining if the results are meaningful or not is the evaluation of the performance of our model. \n",
    "\n",
    "The train-test split is a technique for evaluating the performance of a machine learning algorithm that can use any supervised learning method.\n",
    "\n",
    "The goal is to divide the dataset into two sub-sets:\n",
    "\n",
    "- **Train set**: the sample of data used to fit the model.\n",
    "- **Test set**: the sample of data, unseen during the training, used to evaluate the fit machine learning model.\n",
    "\n",
    "It is essential to point out that the evaluation must be made on data that are not visible to the network during the training. In other words, the objective is to estimate the machine learning model's performance on new data not used to train the model, i.e. the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911e8324",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = create_train_test_dataset(df, train_ratio=0.5, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e53628",
   "metadata": {},
   "source": [
    "### Initializing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a3b2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(in_channels, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0477f609",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "The training will take a few minutes. Notice that the 'Current loss' decreases during the training phase, meaning that the network is learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c1f7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train network\n",
    "def train(model, train_data, test_data, num_epochs):\n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    loss_list = []\n",
    "    loss_test_list = []\n",
    "    for epoch in range(num_epochs):\n",
    "        with alive_bar(len(train_data), title= (f'Epoch {epoch}'), force_tty=True, bar='classic', spinner='dots_waves') as bar:\n",
    "            for batch, (data, targets, _) in enumerate(train_data):\n",
    "                data = data.to(device=device)\n",
    "                targets = targets.to(device=device)\n",
    "\n",
    "                #Forward\n",
    "                scores = model(data)\n",
    "                loss = criterion(scores, targets)\n",
    "\n",
    "                #Backward\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "\n",
    "                # Gradient descent\n",
    "                optimizer.step()\n",
    "                bar()\n",
    "        print(epoch, \"Current Loss:\", loss)\n",
    "        loss_list.append(loss.detach().item())\n",
    "        loss_test_list.append(evaluate_loss(model, test_data, device))\n",
    "        \n",
    "    # Display learning curves\n",
    "    fig = go.Figure(layout=go.Layout(xaxis=dict(title=\"Epochs\"),\n",
    "                                 yaxis=dict(title=\"Loss\"),\n",
    "                                 title = 'Learning curves from train and test set'))\n",
    "\n",
    "    fig.add_scatter(marker=dict(size=7, color=\"dodgerblue\"))\n",
    "    fig.data[-1].x = [i for i in range(len(loss_list))]\n",
    "    fig.data[-1].y = loss_list\n",
    "    fig.data[-1].name = 'train loss'\n",
    "\n",
    "    fig.add_scatter(marker=dict(size=7, color=\"coral\"))\n",
    "    fig.data[-1].x = [i for i in range(len(loss_test_list))]\n",
    "    fig.data[-1].y = loss_test_list\n",
    "    fig.data[-1].name = 'test loss'\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    return loss_list, loss_test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d283ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list, loss_test_list = train(model, train_loader, test_loader, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e72a6a",
   "metadata": {},
   "source": [
    "Looking at learning curve, the network seems to perform pretty well, but let's look at the accuracy and what is predicting wrong and try to understand why it is making mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bd6df6",
   "metadata": {},
   "source": [
    "### Showcases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8bf1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute accuracy  \n",
    "print('Train set:')\n",
    "list_of_train_incorrect_preds, list_of_train_preds = evaluate_score(model, train_loader, device)\n",
    "print('Test set:')\n",
    "list_of_test_incorrect_preds, list_of_test_preds = evaluate_score(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893e0fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_test_incorrect_preds[0][0]\n",
    "mislabeled_image = main_path + 'MedNIST_0.5/' + list_of_test_incorrect_preds[0][0]\n",
    "plt.figure()\n",
    "im = PIL.Image.open(mislabeled_image)\n",
    "plt.imshow(im, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print('Ground Truth: ', get_key(mp, list_of_test_incorrect_preds[0][1]), '- class', list_of_test_incorrect_preds[0][1])\n",
    "print('Predicted class: ', get_key(mp, list_of_test_incorrect_preds[0][2]), '- class', list_of_test_incorrect_preds[0][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843aea25",
   "metadata": {},
   "source": [
    "Even if the Is it the kind of error you were expecting after the first look at the dataset?\n",
    "Run the next cell to see other incorrectly classified samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4debbd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(2, 3, figsize=(10, 10))\n",
    "for i, k in enumerate(random.sample(range(len(list_of_test_incorrect_preds)), 6)):\n",
    "    im = PIL.Image.open(main_path + 'MedNIST_0.5/' + list_of_test_incorrect_preds[k][0])\n",
    "    arr = np.array(im)\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    plt.xlabel({'GT: ': get_key(mp, list_of_test_incorrect_preds[k][1]),\n",
    "                'Pred: ': get_key(mp, list_of_test_incorrect_preds[k][2])})\n",
    "    plt.imshow(arr, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f49ba4",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb6163a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix([v[0] for v in list_of_test_preds],[v[1] for v in list_of_test_preds])\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp = disp.plot(include_values=True, cmap=plt.cm.Blues)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7d16a2",
   "metadata": {},
   "source": [
    "Discuss with your team the possible answer and to have insights, use the following interactive table to explore it more in detail the dataset. Run the cells so you can directly interact with the dataframe: click on the filter button on the up-right side to investigate the dataset.\n",
    "\n",
    "As a reminder the classes and the respespective labels are:\n",
    " - Hand - 0\n",
    " - BreastMRI - 1\n",
    " - ChestCT - 2\n",
    " - HeadCT - 3\n",
    " - AbdomenCT - 4\n",
    " - CXR - 5\n",
    " \n",
    " If you want a suggestion run the hint cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee46658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell if you want a hint\n",
    "hint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d99a529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import data_table\n",
    "data_table.enable_dataframe_formatter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bf7847",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_explore = df.rename(columns={0: 'filename',\n",
    "                                1: 'class label',\n",
    "                                2: 'class name'})\n",
    "df_explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92757ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to check your answer\n",
    "check_MedNIST()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e87b0c",
   "metadata": {},
   "source": [
    "### Training on the full dataset\n",
    "\n",
    "Now that we discovered that the first dataset was biased, let's train the model over a well-balanced dataset and look at the results. We will need to repeat some of the previous steps on the new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf7da8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe creation \n",
    "df_complete, _ = get_MedNIST_dataframe(percentage_to_treat=[1., 1., 1., 1., 1., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4378398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "train_loader_complete, test_loader_complete = create_train_test_dataset(df_complete, train_ratio=0.5, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b877ce0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inizialization\n",
    "model = CNN(in_channels, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd966d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "train(model, train_loader_complete, test_loader_complete, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b601b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train set:')\n",
    "list_prova = evaluate_score(model, train_loader_complete, device)\n",
    "print('Test set:')\n",
    "list_of_test_incorrect_preds = evaluate_score(model, test_loader_complete, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c8edc9",
   "metadata": {},
   "source": [
    "We can notice that the accuracy and performance are improved. But let's look at the wrongly classified samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d762daf7",
   "metadata": {},
   "source": [
    "As we expected at the beginning of the tutorial, after having a first look at the data, the network, even when performing well, still has trouble predicting the Chest and Abdomen classes, since the images are quite similar to each other. \n",
    "\n",
    "Other errors are probably due to the fact that some samples (like hands, CXRs or heads) have a large portion of the image in black or grey and teh network might be confused."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a470c78",
   "metadata": {},
   "source": [
    "### Test on a different image\n",
    "\n",
    "Let's see now how our model behaves when we feed it with a completely new, different image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93ee962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the new image and rezise it\n",
    "single_image = PIL.Image.open(main_path + 'image_number.jpg')\n",
    "resized_image = scipy.ndimage.zoom(single_image, 2.3, order=1)\n",
    "plt.imshow(resized_image, cmap=\"gray\", vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6993deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transoform the image before give it to the model\n",
    "transform = transforms.ToTensor()\n",
    "resized_image.reshape((1, 64, 64))\n",
    "input_image = transform(resized_image).to(device=device)\n",
    "input_image = input_image.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd30f60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the new image\n",
    "model.eval()              # turn the model to evaluate mode\n",
    "with torch.no_grad():     # does not calculate gradient\n",
    "    class_index = model(input_image).argmax()   #gets the prediction for the image's class\n",
    "    \n",
    "print('Prediceted class:', get_key(mp, class_index.item()), '- class label: ', class_index.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73aa29f",
   "metadata": {},
   "source": [
    "As you can see the network is unable to recognize that the image does not belong to any of the classes. Even if the image is not related to the dataset that we used for the training, the model always makes a prediction!\n",
    "\n",
    "Congratulations! You completed this tutorial!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
