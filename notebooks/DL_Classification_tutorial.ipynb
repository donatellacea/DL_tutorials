{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fbdbc75",
   "metadata": {},
   "source": [
    "![logo](https://github.com/donatellacea/DL_tutorials/blob/main/notebooks/figures/1128-191-max.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040a619e",
   "metadata": {},
   "source": [
    "# Classification with Deep Learning \n",
    "---\n",
    "\n",
    "With the term **Machine Learning** (ML) we define a set of algorithms and methods that provide a machine with the ability to learn automatically and improve from experience without being explicitly programmed.\n",
    "When we have labeled data, we can use the label to guide the learning process, and this is called **Supervised learning**. If data are not labeled, it means that we don't have a guide or a supervision, and this is called **Unsupervised learning**.\n",
    "Within Supervised learning we can have two different kind if problems:\n",
    " - **Regression problem**: the task of predicting a contineous quantity,  \n",
    " - **Classification problem**: the task of predicting a label or a class (discrete values).\n",
    "\n",
    "This tutorial will show you how to perform classification with deep Neural Network (NN) on images. We will work with two public datasets, and we will see a binary classification and a multi-class classification problem. \n",
    "\n",
    "In order to start working on the notebook, click on the following button, this will open this page in the Colab environment and you will be able to execute the code on your own.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/donatellacea/DL_tutorials/blob/main/notebooks/DL_Classification_tutorial.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58bec64",
   "metadata": {},
   "source": [
    "## Setup the environment\n",
    "\n",
    "If you already did this step for the Tensorflow Playground tutorial, you can skip the setup section and start with the Import and Install section. Otherwise, complete the next step before starting the tutorial.\n",
    "\n",
    "Now that you are visualizing the notebook in Colab, run the next cell, in order to create a folder in your Google Drive. Alle the files for this tutorial, will be uploaded in this folder. After the first execution you might receive some warning and notification, please follow this instruciotns:\n",
    "1. Warning: This notebook was not authored by Google. Click on Run anyway.\n",
    "2. Permit this notebook to access your Google Drive files? Click on Yes, and select your account.\n",
    "3. Google Drive for desktopÂ wants to access your Google Account. Click on 'Allow'.\n",
    "\n",
    "At this point a folder has been created and you can navigate it trhought the lefthand panel in Colab, you might also have received an email that informs you about the acess on your google Drive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283012ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folder in your Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ea4ba3",
   "metadata": {},
   "source": [
    "Execute the next cells to clone the repository from GitHub, so the important files and notebooks for this tutorial will be downloaded in your working folder on the Drive that you created in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43769c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd drive/MyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eb3263",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/donatellacea/DL_tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26d77c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd DL_tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e277648b",
   "metadata": {},
   "source": [
    "### Import and intall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb7ef57",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install alive_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8fcf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to import the main packages we will use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import sklearn\n",
    "import random\n",
    "random.seed(1)\n",
    "import matplotlib.pyplot as plt \n",
    "import PIL\n",
    "import plotly.graph_objects as go\n",
    "from skimage import io \n",
    "from alive_progress import alive_bar\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1918d1f3",
   "metadata": {},
   "source": [
    "## Binary Classification\n",
    "---\n",
    "\n",
    "In this problem, we will use the Lung CT scans dataset in order to predict whether the patient has Codiv-19 or not. Since the output can be positive or negative, this is a classic example of **binary classification**. \n",
    "\n",
    "### Dataset \n",
    "The dataset, available on Kaggle (https://www.kaggle.com/datasets/luisblanche/covidct), will be downloaded in your google drive folder that we will create in the first step of the tutorial.\n",
    "\n",
    "It counts in a total of 746 images divided as follows:\n",
    "- 397 No Covid\n",
    "- 349 Covid\n",
    "\n",
    "The images, i.e. CT scans, are obtained through Computed Tomography, a medical imaging technique used in radiology (x-ray) to obtain detailed internal images of the body noninvasively for diagnostic purposes. Only with proper training is it possible to interpret the scans, so without a radiology/medical background, it is tough to understand the presence of Covid-19 from the scan. But we will see that a well-trained NN can help the technicians and doctors diagnose this kind of disease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d421c0",
   "metadata": {},
   "source": [
    "Run the next cell to download the data, you should see a folder that contains two sub folder one for each class, Covid and No-Covid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bd0c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path\n",
    "main_path = '/content/drive/MyDrive/DL_tutorials/notebooks/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ce12fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L https://www.dropbox.com/s/ynxtbh7t0mts30k/Dataset_CT_lungs.zip?dl=1 > /content/drive/MyDrive/DL_tutorials/notebooks/Dataset_CT_lungs.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444494c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.unpack_archive(main_path + 'Dataset_CT_lungs.zip', main_path)\n",
    "shutil.rmtree(main_path + '__MACOSX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0103b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the path to each folder\n",
    "data_path = main_path + '/Dataset_CT_lungs/'\n",
    "pos_files = glob.glob(os.path.join(data_path, \"CT_COVID\",'*.*'))\n",
    "neg_files = glob.glob(os.path.join(data_path, 'CT_NonCOVID','*.*'))\n",
    "images = pos_files + neg_files\n",
    "num_total = len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a9bc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 9 random CT scans from the dataset to see how do they look like\n",
    "# random.seed(7)\n",
    "plt.subplots(3, 3, figsize=(8, 8)) \n",
    "num_fig = 9\n",
    "ax_name = ['No Covid'] * num_fig\n",
    "for i, number in enumerate(random.sample(range(num_total), num_fig)):\n",
    "    im = PIL.Image.open(images[number])\n",
    "    arr = np.array(im)\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    if 'CT_COVID' in images[number]:        \n",
    "        ax_name[i] = 'Covid'\n",
    "    plt.xlabel(ax_name[i], fontsize=15)\n",
    "    plt.imshow(arr, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddfe01d",
   "metadata": {},
   "source": [
    "## Multi-class Classification\n",
    "---\n",
    "\n",
    "In this problem, we will use the MedNIST dataset in order to predict whether the image belongs to one of the six possible class. Since the output can be positive or negative, this is a classic example of **multi-class classification**. \n",
    "\n",
    "### Dataset \n",
    "The MedNIST dataset was gathered from several sets from TCIA, the RSNA Bone Age Challenge, and the NIH Chest X-ray dataset.\n",
    "\n",
    "The dataset is kindly made available by Dr. Bradley J. Erickson M.D., Ph.D. (Department of Radiology, Mayo Clinic) under the Creative Commons CC BY-SA 4.0 license. If you use the MedNIST dataset, please acknowledge the source, e.g.\n",
    "\n",
    "https://github.com/Project-MONAI/MONAI/blob/master/examples/notebooks/mednist_tutorial.ipynb.\n",
    "\n",
    "The following commands download and unzip the dataset (~60MB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dee989a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L https://www.dropbox.com/s/1c5em1n5suasf1c/MedNIST.zip?dl=1 > /content/drive/MyDrive/DL_tutorials/notebooks/MedNIST.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8994c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.unpack_archive(main_path + 'MedNIST.zip', main_path)\n",
    "shutil.rmtree(main_path + '__MACOSX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd27de0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82d5129d",
   "metadata": {},
   "source": [
    "#### Define the structure of the convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd937c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=8, kernel_size=(3,3)) #out_channels=32\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3,3)) # in_channels=32\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.lin1 = nn.Linear(3136, 64)\n",
    "        self.lin2 = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x) # test with no dropout\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.lin2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723dfdf5",
   "metadata": {},
   "source": [
    "#### Set up the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3111feff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyperparameters\n",
    "in_channels = 1\n",
    "num_classes = 6\n",
    "lr = 0.0001 #0.0001 good\n",
    "batch_size = 64\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6118cd11",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c31090",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedicalMNIST(Dataset):\n",
    "    def __init__(self, df, root_dir, transform=None):\n",
    "        self.annotations = df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n",
    "        image = io.imread(img_path)\n",
    "        y_label = torch.tensor(int(self.annotations.iloc[index, 1]))\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return (image, y_label, self.annotations.iloc[index, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b98fc4a",
   "metadata": {},
   "source": [
    "#### Create the dataset and train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0fc08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = {}\n",
    "i = 0\n",
    "for category in os.listdir(main_path + \"MedNIST\"):\n",
    "    if category != 'README.md' and not category.startswith(\".\"):\n",
    "        mp[category] = i\n",
    "        i += 1\n",
    "print(mp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a101aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(base_path, name_folder, percentage_to_treat=None):\n",
    "    # this function create a dataframe with the path of files and gt values \n",
    "    # for the classification algorithm with pytorch\n",
    "    # base_path = path for MedMNIST and dataset folders\n",
    "    # name_folder = name of the folder of the new dataset\n",
    "    # percentage_to_treat = list with percentage of files to take from each folder\n",
    "\n",
    "    data_path = base_path + 'MedNIST/'\n",
    "    new_path = base_path + name_folder ### Remove together with relative input\n",
    "    list_of_dirs = []\n",
    "    for name in os.listdir(data_path):\n",
    "        if name != 'README.md' and not name.startswith(\".\"):\n",
    "            list_of_dirs.append(name)\n",
    "    number_of_dirs = len(list_of_dirs)\n",
    "    if percentage_to_treat is None:\n",
    "        percentage_to_treat = [1.] * number_of_dirs\n",
    "\n",
    "    df_new = pd.DataFrame() # columns=['filename', 'groundtruth'])\n",
    "\n",
    "    for i, name in enumerate(list_of_dirs):\n",
    "        current_dir = data_path + name\n",
    "        number_of_files = len(os.listdir(current_dir))\n",
    "        number_of_files_treat = int(percentage_to_treat[i] * number_of_files)\n",
    "\n",
    "        list_copied_train_files = []\n",
    "        with alive_bar(number_of_files_treat, title=name, force_tty=True, bar='classic', spinner='dots_waves') as bar:\n",
    "            for j, number in enumerate(random.sample(range(number_of_files), number_of_files_treat)):\n",
    "                file = os.listdir(current_dir)[number]\n",
    "                list_copied_train_files.append([name + '/' + file, i, name])\n",
    "                bar()\n",
    "                \n",
    "        df_new = pd.concat([df_new, pd.DataFrame(list_copied_train_files)]) #columns=['filename', 'groundtruth', 'class name'])])\n",
    "   \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4961718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = 'prova'\n",
    "df = create_data(main_path, folder_name, percentage_to_treat=[0.01, 0.01, 0.01, 0.05, 0.05, 0.05])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0327914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_total = len(df)\n",
    "num_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eecaa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[2].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a3f2fe",
   "metadata": {},
   "source": [
    "#### Have a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1144ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(4, 4, figsize=(8, 8))\n",
    "random.seed(1) # change this number to create other random images\n",
    "for i, k in enumerate(random.sample(range(len(df)), 16)):\n",
    "    im = PIL.Image.open(main_path + \"MedNIST/\" + df[0].iloc[k])\n",
    "    # im = PIL.Image.open(df[0].iloc[k])\n",
    "\n",
    "    arr = np.array(im)\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.xlabel(df[2].iloc[k])\n",
    "    plt.imshow(arr, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fa136a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a73b13c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
