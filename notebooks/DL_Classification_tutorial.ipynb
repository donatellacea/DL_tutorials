{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fbdbc75",
   "metadata": {},
   "source": [
    "![logo](https://github.com/donatellacea/DL_tutorials/blob/main/notebooks/figures/1128-191-max.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040a619e",
   "metadata": {},
   "source": [
    "# Image classification with Deep Learning \n",
    "---\n",
    "\n",
    "With the term **Machine Learning** (ML) we define a set of algorithms and methods that provide a machine with the ability to learn automatically and improve from experience without being explicitly programmed.\n",
    "When we have labeled data, we can use the label to guide the learning process, and this is called **Supervised learning**. If data are not labeled, it means that we don't have a guide or supervision, and this is called **Unsupervised learning**.\n",
    "Within Supervised learning, we can deal with two different kinds of problems:\n",
    " - **Regression problem**: the task of predicting a continuous quantity\n",
    " - **Classification problem**: the task of predicting a label or a class (discrete values)\n",
    "\n",
    "This tutorial will show you how to perform classification with Deep Neural Network (NN) on images. We will work with two public datasets, and we will see a binary classification and a multi-class classification problem. \n",
    "\n",
    "In order to start working on the notebook, click on the following button, this will open this page in the Colab environment and you will be able to execute the code on your own.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/donatellacea/DL_tutorials/blob/main/notebooks/DL_Classification_tutorial.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58bec64",
   "metadata": {},
   "source": [
    "### Setup the environment\n",
    "\n",
    "**If you already did this step for the Tensorflow Playground tutorial, you can skip the setup section and start with the Import and Install section. Otherwise, complete the next step before starting the tutorial.**\n",
    "\n",
    "Now that you are visualizing the notebook in Colab, run the next cell, in order to create a folder in your Google Drive. All the files for this tutorial will be uploaded to this folder. After the first execution you might receive some warning and notification, please follow these instructions:\n",
    "1. Warning: This notebook was not authored by Google. *Click* on 'Run anyway'.\n",
    "2. Permit this notebook to access your Google Drive files? *Click* on 'Yes', and select your account.\n",
    "3. Google Drive for desktopÂ wants to access your Google Account. *Click* on 'Allow'.\n",
    "\n",
    "At this point, a folder has been created and you can navigate it through the lefthand panel in Colab, you might also have received an email that informs you about the access on your Google Drive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283012ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folder in your Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ea4ba3",
   "metadata": {},
   "source": [
    "Execute the next cells to clone the repository from GitHub, so the important files and notebooks for this tutorial will be downloaded to your working folder on the Drive that you created in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43769c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd drive/MyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eb3263",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/donatellacea/DL_tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26d77c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd DL_tutorials/notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e277648b",
   "metadata": {},
   "source": [
    "### Import and install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea32477f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install alive_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8fcf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to import the main packages we will use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import sklearn\n",
    "import random\n",
    "random.seed(1)\n",
    "import matplotlib.pyplot as plt \n",
    "import PIL\n",
    "import plotly.graph_objects as go\n",
    "import scipy.ndimage\n",
    "from skimage import io \n",
    "from alive_progress import alive_bar\n",
    "from check_file import *\n",
    "from utils import *\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1918d1f3",
   "metadata": {},
   "source": [
    "## Binary Classification\n",
    "---\n",
    "\n",
    "In this problem, we will use the Lung CT scans dataset in order to predict whether the patient has Codiv-19 or not. Since the output can be positive or negative, this is a classic example of **binary classification**. \n",
    "\n",
    "### Dataset \n",
    "The dataset, available on Kaggle (https://www.kaggle.com/datasets/luisblanche/covidct), will be downloaded in your google drive folder that we created in the first step of the tutorial.\n",
    "\n",
    "The dataset counts a total of 746 images divided as follows:\n",
    "- 397 No Covid\n",
    "- 349 Covid\n",
    "\n",
    "The images, i.e. CT scans, are obtained through Computed Tomography, a medical imaging technique used in radiology (X-ray) to obtain noninvasively detailed internal images of the body for diagnostic purposes. Only with proper training is it possible to interpret the scans, so without a radiology/medical background, it is tough to understand the presence of Covid-19 from the scan. But we will see that a well-trained NN can help the technicians and doctors diagnose this kind of disease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d421c0",
   "metadata": {},
   "source": [
    "Run the next cell to download the data, you should see in your Drive a folder that contains two subfolders, one for each class, Covid and No-Covid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bd0c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path\n",
    "main_path = '/content/drive/MyDrive/DL_tutorials/notebooks/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac85b2c",
   "metadata": {},
   "source": [
    "The next cell will download the dataset to your Google Drive. From there you can eventually look at the images or download them on your own machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ce12fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L https://www.dropbox.com/s/ynxtbh7t0mts30k/Dataset_CT_lungs.zip?dl=1 > /content/drive/MyDrive/DL_tutorials/notebooks/Dataset_CT_lungs.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f0f04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.unpack_archive(main_path + 'Dataset_CT_lungs.zip', main_path)\n",
    "shutil.rmtree(main_path + '__MACOSX')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7539cf63",
   "metadata": {},
   "source": [
    "Now, let's have a look at the kind of images we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0103b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the path to each folder\n",
    "data_path = main_path + '/Dataset_CT_lungs/'\n",
    "pos_files = glob.glob(os.path.join(data_path, \"CT_COVID\",'*.*'))\n",
    "neg_files = glob.glob(os.path.join(data_path, 'CT_NonCOVID','*.*'))\n",
    "images = pos_files + neg_files\n",
    "num_total = len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a9bc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 9 random CT scans from the dataset to see how they look like\n",
    "plt.subplots(3, 3, figsize=(8, 8)) \n",
    "num_fig = 9\n",
    "ax_name = ['No Covid'] * num_fig\n",
    "for i, number in enumerate(random.sample(range(num_total), num_fig)):\n",
    "    im = PIL.Image.open(images[number])\n",
    "    arr = np.array(im)\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    if 'CT_COVID' in images[number]:        \n",
    "        ax_name[i] = 'Covid'\n",
    "    plt.xlabel(ax_name[i], fontsize=15)\n",
    "    plt.imshow(arr, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e170a1",
   "metadata": {},
   "source": [
    "Let's see how the [Teachable Machine](https://teachablemachine.withgoogle.com/) is able to detect Covid from the CT scans. If you didn't do the previous tutorial on the Teachable Machine, and you have any doubt about it, you can open the respective [notebook](https://nbviewer.org/github/donatellacea/DL_tutorials/blob/main/notebooks/Teachable_machine_tutorial.ipynb) where you can find some more information.\n",
    "\n",
    "You can upload the dataset directly from the drive, but it might be quicker to download the dataset on your own computer and do the upload from there, so it will take only a couple of minutes.\n",
    "\n",
    "Create the label for the two classes and upload the data (Do not use all the images, but keep a couple of images from each class, so that you can use them later in the preview.)\n",
    "\n",
    "Now, start the training of the teachable machine with the panel 'Under the Hood' opened to look at the learning curves and the accuracies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f499ce",
   "metadata": {},
   "source": [
    "### Model evaluation - learning curves\n",
    "\n",
    "Your goal is to check whether the model is able to recognize the disease or not and its performances. To test the model you can either upload a single scan from the folders and see if the predicted output is correct.\n",
    "But to have a wider comprehension of what is happening, open the 'Under the hood' panel and check the learning curves during the training.\n",
    "\n",
    "**Accuracy per epoch**\n",
    "\n",
    "Accuracy is one of the evaluation metrics we can use to evaluate how good a model is. It can be defined as the number of samples correctly classified over the total number of samples.\n",
    "\n",
    "<center>\n",
    "$\\text{Accuracy} = \\dfrac{\\text{# of sample correctly classified}}{\\text{total # of sample}}$\n",
    "</center>\n",
    "\n",
    "\n",
    "Looking at the accuracy plot over the epochs we can state that the model is not performing badly.\n",
    "\n",
    "\n",
    "\n",
    "**Loss per epoch**\n",
    "\n",
    "Another interesting way to see if the model is correctly learning is to look at the loss function at different epochs. A NN works trying to minimize the difference between the prediction and the label, this is usually described through a *loss function*. If the loss function is decreasing over time, it means that the network is learning.\n",
    "\n",
    "What is the difference between the training and the test curve? According to you, which might be the reason? Discuss it with your team and think about possible changes that could improve the model's performance.\n",
    "Run the next cell to check whether your answer is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01cf2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to have the answer to the previous question \n",
    "check_task_tm_2_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd33558",
   "metadata": {},
   "source": [
    "**Confusion matrix**\n",
    "\n",
    "Sometimes accuracy is not always enough to evaluate a model. Let's see that with an example. Assume that we have 10 patients and only one of them has a disease. If our model predicts that a patient is always healthy, it means that its accuracy would be $\\frac{9}{10} = 0.90$, which is pretty high, even if the model is not giving us relevant information. Indeed, in this case, we are more interested in detecting the disease instead of only having such high accuracy and missing relevant information.\n",
    "\n",
    "For this reason, it is interesting to introduce other metrics such as sensitivity and specificity.\n",
    "- **sensitivity**: that represents the true positive rate (in terms of probability is the probability of predicting positive given that the patient has the disease);\n",
    "- **specificity**: that represents the true negative rate (i.e. the probability of predicting negative, given that the patient is healthy).\n",
    "\n",
    "This information is usually summarized in a table, called 'confusion matrix', used to look at the performance of the classifier in form of a table. The rows represent the Groundtruth (GT) and the columns are the output predicted by the model. Each cell coincides with the number of the element corresponding to each GT/model prediction combination and is called:\n",
    "- True Positive (TP): when both GT and the prediction are positive\n",
    "- False Negative (FN): when the GT is positive but the output is negative\n",
    "- False Positive (FP): when the GT is negative (i.e. healthy patient) but the output is positive\n",
    "- True negative: when both GT and the prediction are negative\n",
    "\n",
    "In medical applications, especially FN and FP should be reduced as much as possible, in order to avoid missing the detection of a disease or alarming people who are actually in good health.\n",
    "\n",
    "<div>\n",
    "<img src=\"https://github.com/donatellacea/DL_tutorials/blob/main/notebooks/figures/confusionmatrix.png?raw=true\" width=\"300\" height=\"200\"/>\n",
    "</div>\n",
    "\n",
    "To see the confusion matrix of our model, click the confusion matrix button in the 'Under the hood' panel. You will notice that, even if the model is performig well, there are still some FP and TN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763da77b",
   "metadata": {},
   "source": [
    "As you can see the DL algorithm, even if it is not perfect, is able to recognize Covid and no-Covid cases, a difficult task for a technician to perform and impossible for ordinary people with no medical background to undertake.\n",
    "\n",
    "Now that we explored a binary classification example through the Teachable Machine, let's have a closer look at a NN over a different dataset for multi-class classification. In the next part of the tutorial, you will directly see a coding example of a deep neural network, in order to see what hides behind an interface like the one we used in the first section of this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddfe01d",
   "metadata": {},
   "source": [
    "## Multi-class Classification\n",
    "---\n",
    "\n",
    "In this problem, we will use the MedNIST dataset in order to predict whether the image belongs to one of the six possible classes. Therefore, this is a classic example of **multi-class classification**. \n",
    "\n",
    "### Dataset \n",
    "\n",
    "The [MedNIST](https://github.com/Project-MONAI/MONAI/blob/master/examples/notebooks/mednist_tutorial.ipynb), was gathered from several sets from TCIA, the RSNA Bone Age Challenge, and the NIH Chest X-ray dataset and is kindly made available by Dr. Bradley J. Erickson M.D., Ph.D. (Department of Radiology, Mayo Clinic).\n",
    "\n",
    "The original dataset counts more than 50k images, which we reduced for the purposes of this tutorial. Run the following commands to download the dataset to your Drive and unzip it. Note that this step might take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7288aacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L https://www.dropbox.com/s/wrbfk4o63f3cn5k/MedNIST_0.5.zip?dl=1 > /content/drive/MyDrive/DL_tutorials/notebooks/MedNIST_0.5.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805864b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.unpack_archive(main_path + 'MedNIST_0.5.zip', main_path)\n",
    "shutil.rmtree(main_path + '__MACOSX')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6791e6c9",
   "metadata": {},
   "source": [
    "Now let's have a look at the data.\n",
    "First, we need to save all the image names in a dataframe (df), i.e. a table, to have direct and quick access to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e9d0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, mp = get_MedNIST_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4f59be",
   "metadata": {},
   "source": [
    "Now, let's see how many classes we have, their names, and labels. And also have a look at how a dataframe looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ad177b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d99a529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import data_table\n",
    "data_table.enable_dataframe_formatter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bf7847",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_explore = df.rename(columns={0: 'filename',\n",
    "                                1: 'class label',\n",
    "                                2: 'class name'})\n",
    "df_explore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b40bce",
   "metadata": {},
   "source": [
    "Before we start building our classification model, run the next cell and take some time to analyze the images, and try to anticipate how the network will behave.\n",
    "\n",
    "Which classes do you expect will be harder to classify and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3acc2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(4, 4, figsize=(8, 8))\n",
    "random.seed(6) \n",
    "for i, k in enumerate(random.sample(range(len(df)), 16)):\n",
    "    im = PIL.Image.open(main_path + \"MedNIST_0.5/\" + df[0].iloc[k])\n",
    "    arr = np.array(im)\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.xlabel(df[2].iloc[k])\n",
    "    plt.imshow(arr, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adf38eb",
   "metadata": {},
   "source": [
    "### Define the structure of the Convolutional Neural Network (CNN)\n",
    "\n",
    "The network we build is formed by several hidden layers, as shown in the image ([Image credit](https://www.mathworks.com/videos/introduction-to-deep-learning-what-are-convolutional-neural-networks--1489512765771.html)).\n",
    "\n",
    "<div>\n",
    "<img src=\"https://github.com/donatellacea/DL_tutorials/blob/main/notebooks/figures/cnn.png?raw=true\" width=\"500\" height=\"300\"/>\n",
    "</div>\n",
    "\n",
    "The explanation of the layers is in the extra material session at the end of this notebook. Now we only focus on the layer that  gives the name to the whole architecture.\n",
    "\n",
    "**Convolutional layer**: convolution is a mathematical word for what is essentially a moving window or filter across the image being studied. As the filter slides over the images, the dot products between the pixel values and the filter are computed, creating the so-called convolved feature map (see image below - [credit](https://media4.giphy.com/media/i4NjAwytgIRDW/giphy.gif?cid=ecf05e477z2u4ge19e34frejcm5q6o228fiyohcg0viafep7&rid=giphy.gif&ct=g)).\n",
    "<div>\n",
    "<img src=\"https://media4.giphy.com/media/i4NjAwytgIRDW/giphy.gif?cid=ecf05e477z2u4ge19e34frejcm5q6o228fiyohcg0viafep7&rid=giphy.gif&ct=g\" width=\"300\" height=\"200\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e79038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=8, kernel_size=(3,3))\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3,3)) \n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.lin1 = nn.Linear(3136, 64)\n",
    "        self.lin2 = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x) \n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.lin2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55df03bc",
   "metadata": {},
   "source": [
    "### Set up the parameters\n",
    "\n",
    "We define the input/output and the hyperparameters which, unlike the parameters that describe the model itself, characterize the learning process. In particular, we define:\n",
    "\n",
    "- in_channels: number of input channels\n",
    "- num_classes = number of possible output., i.e. the class that can be predicted (in the case of the Covid dataset the number of classes is 2; in this case, the classes present in the dataset are 6)\n",
    "- lr = learning rate is the step size during the training process that determines the speed and how well the model trains.\n",
    "- batch_size = number of samples processed before the model is updated, it's often set as a power of 2.\n",
    "- num_epochs = number of iterations over the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79b3604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device in case it is possible to access a GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Number of input and output\n",
    "in_channels = 1\n",
    "num_classes = 6\n",
    "\n",
    "# Hyperparameters\n",
    "lr = 0.0001\n",
    "batch_size = 64\n",
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6899cc38",
   "metadata": {},
   "source": [
    "### Train-test split\n",
    "\n",
    "No matter if we are dealing with classification or regression problems, a crucial aspect of determining if the results are meaningful or not is the evaluation of the performance of our model. \n",
    "\n",
    "The train-test split is a technique for evaluating the performance of a machine learning algorithm that can use any supervised learning method.\n",
    "\n",
    "The goal is to divide the dataset into two sub-sets:\n",
    "\n",
    "- **Train set**: the sample of data used to fit the model.\n",
    "- **Test set**: the sample of data, unseen during the training, used to evaluate the fit machine learning model.\n",
    "\n",
    "It is essential to point out that the evaluation must be made on data that are not visible to the network during the training. In other words, the objective is to estimate the machine learning model's performance on new data not used to train the model, i.e. the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911e8324",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = create_train_test_dataset(df, train_ratio=0.5, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e53628",
   "metadata": {},
   "source": [
    "### Initializing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a3b2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(in_channels, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0477f609",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "The training will take a few minutes. Notice that the 'Current loss' decreases during the training phase, meaning that the network is learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c1f7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train network\n",
    "def train(model, train_data, test_data, num_epochs):\n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    loss_list = []\n",
    "    loss_test_list = []\n",
    "    for epoch in range(num_epochs):\n",
    "        with alive_bar(len(train_data), title= (f'Epoch {epoch}'), force_tty=True, bar='classic', spinner='dots_waves') as bar:\n",
    "            for batch, (data, targets, _) in enumerate(train_data):\n",
    "                data = data.to(device=device)\n",
    "                targets = targets.to(device=device)\n",
    "\n",
    "                #Forward\n",
    "                scores = model(data)\n",
    "                loss = criterion(scores, targets)\n",
    "\n",
    "                #Backward\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "\n",
    "                # Gradient descent\n",
    "                optimizer.step()\n",
    "                bar()\n",
    "        print(epoch, \"Current Loss:\", loss)\n",
    "        loss_list.append(loss.detach().item())\n",
    "        loss_test_list.append(evaluate_loss(model, test_data, device))\n",
    "        \n",
    "    # Display learning curves\n",
    "    fig = go.Figure(layout=go.Layout(xaxis=dict(title=\"Epochs\"),\n",
    "                                 yaxis=dict(title=\"Loss\"),\n",
    "                                 title = 'Learning curves from train and test set'))\n",
    "\n",
    "    fig.add_scatter(marker=dict(size=7, color=\"dodgerblue\"))\n",
    "    fig.data[-1].x = [i for i in range(len(loss_list))]\n",
    "    fig.data[-1].y = loss_list\n",
    "    fig.data[-1].name = 'train loss'\n",
    "\n",
    "    fig.add_scatter(marker=dict(size=7, color=\"coral\"))\n",
    "    fig.data[-1].x = [i for i in range(len(loss_test_list))]\n",
    "    fig.data[-1].y = loss_test_list\n",
    "    fig.data[-1].name = 'test loss'\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    return loss_list, loss_test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d283ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list, loss_test_list = train(model, train_loader, test_loader, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e72a6a",
   "metadata": {},
   "source": [
    "Looking at the learning curve, the network seems to perform pretty well, let's have a look also at the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8bf1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute accuracy  \n",
    "print('Train set:')\n",
    "list_of_train_incorrect_preds, list_of_train_preds = evaluate_score(model, train_loader, device)\n",
    "print('Test set:')\n",
    "list_of_test_incorrect_preds, list_of_test_preds = evaluate_score(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d338ae",
   "metadata": {},
   "source": [
    "The global accuracy looks pretty high, but let's look at the errors the network is doing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bd6df6",
   "metadata": {},
   "source": [
    "### Showcases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893e0fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_test_incorrect_preds[0][0]\n",
    "mislabeled_image = main_path + 'MedNIST_0.5/' + list_of_test_incorrect_preds[0][0]\n",
    "plt.figure()\n",
    "im = PIL.Image.open(mislabeled_image)\n",
    "plt.imshow(im, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print('Ground Truth: ', get_key(mp, list_of_test_incorrect_preds[0][1]), '- class', list_of_test_incorrect_preds[0][1])\n",
    "print('Predicted class: ', get_key(mp, list_of_test_incorrect_preds[0][2]), '- class', list_of_test_incorrect_preds[0][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843aea25",
   "metadata": {},
   "source": [
    "The previous cell shows a mislabeled class, probably you would expect the network to be wrong for this class.\n",
    "Let's have a look at other examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4debbd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(2, 3, figsize=(10, 10))\n",
    "for i, k in enumerate(random.sample(range(len(list_of_test_incorrect_preds)), 6)):\n",
    "    im = PIL.Image.open(main_path + 'MedNIST_0.5/' + list_of_test_incorrect_preds[k][0])\n",
    "    arr = np.array(im)\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    plt.xlabel({'GT: ': get_key(mp, list_of_test_incorrect_preds[k][1]),\n",
    "                'Pred: ': get_key(mp, list_of_test_incorrect_preds[k][2])})\n",
    "    plt.imshow(arr, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fddfff1",
   "metadata": {},
   "source": [
    "It seems that several times the network predicts a 'Chest' even though it is clearly not the case. To investigate more the kind of errors the network is doing, plot the confusion matrix and look at the accuracy per each class. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35823a16",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d75e4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix([v[0] for v in list_of_test_preds],[v[1] for v in list_of_test_preds])\n",
    "display_labels = list(mp.keys())\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=display_labels)\n",
    "disp = disp.plot(include_values=True, cmap=plt.cm.Blues, xticks_rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55db3995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy per class\n",
    "for x, acc in enumerate(cm.diagonal()/cm.sum(axis=1)):\n",
    "    print(get_key(mp, x), ' - ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7d16a2",
   "metadata": {},
   "source": [
    "**Discuss with your team** the possible reason why we only have such poor accuracy in certain classes.\n",
    "\n",
    "If you want you can also go up to the dataframe we printed at the beginning of this part of the tutorial, and explore the dataset more in detail, clicking on the filter button on the up-right side.\n",
    "\n",
    "In case you need a suggestion to understand why the accuracy is so low in certain classes, run the hint cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882c1c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell if you want a hint otherwise execute the next cells\n",
    "hint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92757ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to check your answer\n",
    "check_MedNIST()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e87b0c",
   "metadata": {},
   "source": [
    "### Training on the full dataset\n",
    "\n",
    "Now that we discovered that the dataset we used was biased, let's train the model over the well-balanced dataset (same number of samples for each class) and look at the results. We will need to repeat some of the previous steps on the new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf7da8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe creation \n",
    "df_complete, _ = get_MedNIST_dataframe(percentage_to_treat=[1., 1., 1., 1., 1., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4378398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "train_loader_complete, test_loader_complete = create_train_test_dataset(df_complete, train_ratio=0.5, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b877ce0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inizialization\n",
    "model = CNN(in_channels, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd966d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "loss_list_complete, loss_test_list_complete = train(model, train_loader_complete, test_loader_complete, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dbea68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train set:')\n",
    "list_of_train_incorrect_preds_complete, list_of_train_preds_complete = evaluate_score(model, train_loader_complete, device)\n",
    "print('Test set:')\n",
    "list_of_test_incorrect_preds_complete,  list_of_test_preds_complete = evaluate_score(model, test_loader_complete, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1470c8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_complete = confusion_matrix([v[0] for v in list_of_test_preds_complete],[v[1] for v in list_of_test_preds_complete])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_complete, display_labels=display_labels)\n",
    "disp = disp.plot(include_values=True, cmap=plt.cm.Blues, xticks_rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0181badc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy per class\n",
    "for x, acc in enumerate(cm_complete.diagonal()/cm_complete.sum(axis=1)):\n",
    "    print(get_key(mp, x), ' - ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c8edc9",
   "metadata": {},
   "source": [
    "We can conclude that not only the global accuracy is improved, but also that every single class has indicatively the same accuracy value, meaning that the network is properly learning to classify images, without sub-representing any class.\n",
    "\n",
    "The goal of this tutorial was to show the difference between an imbalanced and a well-balanced dataset, most of the time it won't be possible to add more data like we did today, but there are techniques that can be used to treat an imbalanced dataset (i.e. use weighted loss functions or resample the dataset). The most important thing is to be aware of the existence of this phenomenon in order to find the best way to deal with it and avoid missing important pieces of information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449ec84c",
   "metadata": {},
   "source": [
    "### Test on a different image\n",
    "\n",
    "Finally, let's see now how our model behaves when we feed it with a completely new, different image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f87017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the new image and rezise it\n",
    "single_image = PIL.Image.open(main_path + 'image_number.jpg')\n",
    "resized_image = scipy.ndimage.zoom(single_image, 2.3, order=1)\n",
    "plt.imshow(resized_image, cmap=\"gray\", vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45343a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transoform the image before give it to the model\n",
    "transform = transforms.ToTensor()\n",
    "resized_image.reshape((1, 64, 64))\n",
    "input_image = transform(resized_image).to(device=device)\n",
    "input_image = input_image.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199d0263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the new image\n",
    "model.eval()              # turn the model to evaluate mode\n",
    "with torch.no_grad():     # does not calculate gradient\n",
    "    class_index = model(input_image).argmax()   #gets the prediction for the image's class\n",
    "    \n",
    "print('Prediceted class:', get_key(mp, class_index.item()), '- class label: ', class_index.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a959bc2",
   "metadata": {},
   "source": [
    "As you can see the network is unable to recognize that the image does not belong to any of the classes. Even if the image is not related to the dataset that we used for the training, the model always makes a prediction!\n",
    "\n",
    "---\n",
    "\n",
    "Congratulations! You completed this tutorial!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8dde3f",
   "metadata": {},
   "source": [
    "### Extra material\n",
    "\n",
    "Here you can find other details about the network architecture, in particular the explanation of the other layers.\n",
    "\n",
    "**Max pooling layer**: It is another sliding window type technique, but instead of applying weights as in the convolution, it applies the max function over the contents of the window. A pooling layer is a way to subsample an input feature map or output from the convolutional layer that has already extracted salient features from an image, this is also called downsampling.\n",
    "\n",
    "**Dropout layer**: dropout removes a percentage of the neuron connections - helping to prevent overfitting by reducing the feature space for convolutional and, especially, dense layers.\n",
    "\n",
    "**Linear layer**: The linear layer is used in the final stages of the neural network. It is also called a fully connected layer. This layer helps in changing the dimensionality of the output from the preceding layer so that the model can easily define the relationship between the values of the data and give the final probabilities for each label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4921c9",
   "metadata": {},
   "source": [
    "### Extra exercise\n",
    "\n",
    "Try to solve this small exercise and review what we learned.\n",
    "\n",
    "According to what we explained, could you compute the sensitivity and specificity of the Teachable Machine model that detects Covid from CT scans? \n",
    "Look again at the confusion matrix in the 'Under the hood panel', insert the data and your solution in the following cell and run it to check whether your answer is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b394733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsitute None with the values that you read in the confusion matrix created on the Teachable Machine\n",
    "confusion_matrix = []\n",
    "confusion_matrix.append(None) # 'Class covid & Pred Covid'\n",
    "confusion_matrix.append(None) # 'Class covid & Pred No Covid'\n",
    "confusion_matrix.append(None) # 'Class No Covid & Pred Covid'\n",
    "confusion_matrix.append(None) # 'Class No Covid & Pred No Covid'\n",
    "\n",
    "#Subsitute None in the specificity and sensitivity field with your solution (approx at the order 10^-2)\n",
    "sensitivity = None\n",
    "specificity = None\n",
    "\n",
    "check_task_tm_2_2(confusion_matrix, sensitivity, specificity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
